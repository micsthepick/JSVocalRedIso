// based on vocalrediso.ny, a built in nyquist filter for audacity: Released under terms of the GNU General Public License version 2
// uses some code from https://github.com/Nbickford/REAPERDenoiser

desc: vocal removal/isolation (MDCT version)
//tags: processing vocals stereo
//author: Michael Pannekoek

slider1:0<-100,100,0.1>dry mix
slider2:0<-100,100,0.1>C mix (Vocals)
slider3:0<-5,5,0.001>strength at Low Cut
slider4:0<-5,5,0.001>strength at High Cut
slider5:80<0,24000,10>Low Cut (Vocals)
slider6:24000<0,24000,10>High Cut (Vocals)
slider7:0<-90,90,0.1>Phase (Degrees)
slider8:90<1,180,0.1>Phase width at Low Cut (Degrees)
slider9:90<1,180,0.1>Phase width at High Cut (Degrees)
slider10:1<0,1,0.05>Attenuate if different volume
slider11:1<0,1,1{No,Yes}>undo input corrections
slider12:0<-180,180,0.05>Phase2 (Degrees)

in_pin:left input
in_pin:right input
out_pin:left output
out_pin:right output


@init
_memory_index = 0;
// init variables
// buffers
// FFT - fft window size (will be constant)
SIZE = 4096;
SIZEMINUSONE = SIZE-1;
DOUBLESIZE = SIZE*2;
HALFSIZE = SIZE/2;
// track how many half frames of delay from the start we are
// to mute the first inital buffers
silence = 2;
samples_collected = 0;


// fft has real and complex values thus is twice as large
// set each buffer to the offsef from the last to make it easier to move them around
_memory_index = (buffer_MDCT_real_L = _memory_index) + SIZE;
_memory_index = (buffer_MDCT_imag_L = _memory_index) + SIZE;
_memory_index = (buffer_MDCT_real_R = _memory_index) + SIZE;
_memory_index = (buffer_MDCT_imag_R = _memory_index) + SIZE;
_memory_index = (buffer_input_L = _memory_index) + srate;
_memory_index = (buffer_input_R = _memory_index) + srate;
_memory_index = (buffer_output_L = _memory_index) + srate;
_memory_index = (buffer_output_R = _memory_index) + srate;
_memory_index = (buffer_param_strength = _memory_index) + SIZE/2;
_memory_index = (buffer_param_phase_width = _memory_index) + SIZE/2;
freembuf(_memory_index);

// track the buffer index
buffer_index = 0;

// tell reaper what delay this plugin will introduce,
// so that it can be compensated for
pdc_delay = SIZE;
// delay is one full buffer
pdc_bot_ch = 0; pdc_top_ch = 2;
// which channels are delayed
// (channel number must be greater than or equal to 0,
// but less than 2, so 0 and 1 - LR output).


@slider
// convert low cut and high cut to bins every time a slider is changed
low_bin = min(slider5, slider6) / srate * SIZE;
high_bin = max(slider6, slider5) / srate * SIZE;
// convert percentage to raw scale factor
dry_mix = slider1/100;
wet_mix = slider2/100;
low_strength = slider3;
high_strength = slider4;
phase_width_low = slider8*$pi/180;
phase_width_high = slider9*$pi/180;
cosine = cos(slider7*$pi/180);
sine = sin(slider7*$pi/180);
cosine2 = cos(slider12*$pi/180);
sine2 = sin(slider12*$pi/180);
// fill buffer_param_strength and buffer_param_phase_width
bi = 0;
loop(SIZE,
	bi >= low_bin && bi < high_bin ?
	(
		// only set values for the appropriate frequency range
		frac = (bi - low_bin)/(high_bin - low_bin - 1);
		frac = max(0, min(1, frac));
		// fraction of progress through range [lowBin, highBin)
		strength = low_strength * (1 - frac) + high_strength * frac;
		buffer_param_strength[bi] = 10^strength;
		// precaculate strength (actual value should be positive, so it makes
		// sense to take the power of ten, but only after the
		// linear mapping over the spectrum is done.
		phase_width = phase_width_low * (1 - frac) + phase_width_high * frac;
		buffer_param_phase_width[bi] = phase_width;
		// precalculate phase width
	);

	bi += 1;
	// next index
);


@sample
// store raw in input buffer
buffer_input_L[buffer_index] = spl0;
buffer_input_R[buffer_index] = spl1;

// that's a lowercase L in spl, not the number 1.
// spl0 corresponds to L, spl1 corresponds to R.

samples_collected += 1;

// once we reach the end of a tile:
samples_collected >= HALFSIZE ?
(
	// make silence go to 0
	silence > 0 ? silence -= 1;
	samples_collected = 0;
	// wrap back to 0 on the tile

	// move input to buffer_MDCT_*
	so = buffer_index - SIZE + 1 + srate;
	bi = 0;
	loop(SIZE,
		buffer_MDCT_real_L[bi] = buffer_input_L[(so + bi) % srate];
		buffer_MDCT_imag_L[SIZEMINUSONE-bi] = buffer_input_L[(so + bi) % srate];
		buffer_MDCT_real_R[bi] = buffer_input_R[(so + bi) % srate];
		buffer_MDCT_imag_R[SIZEMINUSONE-bi] = buffer_input_R[(so + bi) % srate];
		
		bi += 1;
	);

	// compute MDCT
	mdct(buffer_MDCT_real_L, SIZE);
	mdct(buffer_MDCT_imag_L, SIZE);
	mdct(buffer_MDCT_real_R, SIZE);
	mdct(buffer_MDCT_imag_R, SIZE);

	// Compute center:
	// Make a weighted center (mono with respect to phase)
	// that can be substracted from L&R
	// we start off with the fft of the mid channel in the fftBuffer
	bi = 0;
	loop(HALFSIZE,
		mult = -1 ^ (bi % 2);
		// get dry fft coefficeients
		L_real = buffer_MDCT_real_L[bi];
		R_real = buffer_MDCT_real_R[bi];
		L_imag = buffer_MDCT_imag_L[bi] * mult;
		R_imag = buffer_MDCT_imag_R[bi] * mult;
		
		// input corrections
		// first, change the phase of L based on phase2:
		L_real_twisted = L_real*cosine2 + L_imag*sine2;
		l_imag_twisted = L_imag*cosine2 - L_real*sine2;

		// now mix L&R together based on phase
		R_real_rotated = R_real*cosine + L_real_twisted*sine;
		R_imag_rotated = R_imag*cosine + l_imag_twisted*sine;
		L_real_rotated = L_real_twisted*cosine - R_real*sine;
		L_imag_rotated = l_imag_twisted*cosine - R_imag*sine;
		
		low_bin <= bi && bi < high_bin ?
		(
			// apply  vocal reduction algorithm only in the right bands
			strength = buffer_param_strength[bi];
			// get strength
			phase_width = buffer_param_phase_width[bi];
			// get phase width
			norm_L = sqrt(sqr(L_real_rotated) + sqr(L_imag_rotated));
			norm_R = sqrt(sqr(R_real_rotated) + sqr(R_imag_rotated));
			w1 = acos((L_real_rotated * R_real_rotated + L_imag_rotated * R_imag_rotated) / (norm_L * norm_R)) / phase_width;
			weight = (1 - min(1, w1) ^ strength) * (
				1 - (sqr(norm_L - norm_R)/sqr(norm_L + norm_R))
			) ^ (strength * slider10) / 2;

			c_real = (L_real_rotated + R_real_rotated) * weight;
			c_imag = (L_imag_rotated + R_imag_rotated) * weight;
			// isolate the mid fft (can just sum real and imaginary component
			// since fft is a linear operator)
		) : (
			// let wet signal have 0 for fft coefficients when out of bounds
			C_real = 0;
			C_imag = 0;
		);

		// apply wet dry mix
		out_L_real = L_real_rotated * dry_mix + C_real * wet_mix;
		out_L_imag = L_imag_rotated * dry_mix + C_imag * wet_mix;
		out_R_real = R_real_rotated * dry_mix + C_real * wet_mix;
		out_R_imag = R_imag_rotated * dry_mix + C_imag * wet_mix;

		// apply reverse of input corrections
		slider11 != 0 ? (
			// unmix L & R
			new_L_real = out_L_real*cosine + out_R_real*sine;
			new_L_imag = out_L_imag*cosine + out_R_imag*sine;
			out_R_real = out_R_real*cosine - out_L_real*sine;
			out_R_imag = out_R_imag*cosine - out_L_imag*sine;
			
			// revert phase change to L
			out_L_real = new_L_real*cosine2 - new_L_imag*sine2;
			out_L_imag = new_L_imag*cosine2 + new_L_real*sine2;
		);

		// copy back to buffer_MDCT_real_L and buffer_MDCT_real_R
		buffer_MDCT_real_L[bi] = out_L_real;
		buffer_MDCT_real_R[bi] = out_R_real;

		bi += 1;
	);

	// take IMDCT of buffer_MDCT_real_L and buffer_MDCT_real_R
	imdct(buffer_MDCT_real_L, SIZE);
	imdct(buffer_MDCT_real_R, SIZE);

	// add to output buffer
	so = buffer_index;
	bi = 0;
	loop(SIZE,
		buffer_output_L[(so + bi) % srate] += buffer_MDCT_real_L[bi];
		buffer_output_R[(so + bi) % srate] += buffer_MDCT_real_R[bi];
		
		bi += 1;
	);
);


// output samples
//output_index = (buffer_index - fft_size) % srate;
out_L = buffer_output_L[buffer_index];
out_R = buffer_output_R[buffer_index];

// clear the sample just read
buffer_output_L[buffer_index] = 0;
buffer_output_R[buffer_index] = 0;

// output audio
silence == 0 ? (
	spl0 = out_L;
	spl1 = out_R;
) : spl0 = spl1 = 0;

buffer_index = (buffer_index + 1) % srate;

// sliders are serialized automatically
// thus nothing to serialize
